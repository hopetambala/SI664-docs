# MySQL: Creating a database using flat files

Last week a couple students requested a tutorial that explores the process of importing a data 
set saved as a flat file (*.csv) into a relational MySQL database. Below is a walk-through of the
 steps involved in building a `video_games` sales database using a [video games sales](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings) data set sourced from Kaggle. 

## 1.0 Python code, SQL script, and *.csv files
The Python code, SQL script, and *.csv files are in the [SI664-Scripts](https://github.com/UMSI-SI664-2018Fall/SI664-scripts) repo, organized as follows:

```
scripts/
  input/
     csv/
       video_game_sales-20161222.csv
     sql/
       video_games.sql
  output/
       video_games/
         video_game_developers.csv
         video_game_genres.csv
         video_game_platforms.csv
         video_game_publishers.csv
         video_game_ratings.csv
         video_game_sales_trimmed.csv
  run_mysql_script.py
  video_games_inspector.py
```

## 2.0 Pre-import work
The Python [Pandas](https://pandas.pydata.org/) library was leveraged in `video_games_inspector
.py` in order to perform a few pre-import tasks such as generating csv files for a number of 
"lookup" tables. Due to inconsistencies in the original Kaggle csv file as regards whitespace 
handling a new source file was generated after applying a lambda function designed to strip both 
leading and trailing whitespace from each string in the data set. This helped ensure that the csv
 files generated by use of the Pandas library would yield consistent string values (when 
 comparing both matching characters and, importantly, the length of the string) across the csv 
 files used to populate the database. 

```python
def trim_columns(data_frame):
	"""
	:param data_frame:
	:return: trimmed data frame
	"""
	trim = lambda x: x.strip() if type(x) is str else x
	return data_frame.applymap(trim)
```

## 3.0 The SQL script
The `video_games.sql` script is composed of four sections:

* 1.0 Setup
* 2.0 "Lookup" tables creation/data import
* 3.0 Core entity and associate tables creation/data import
* 4.0 Clean up

The script is executed using the Python `run_mysql_script.py` script along with a yaml 
configuration file that supplies the MySQL connection settings.

```commandline
$ python3 run_mysql_script.py -c config/video_games.yaml -p input/sql/video_games.sql
```

The `run_mysql_script.py` script treats the SQL script as a single transaction and will rollback 
all intended changes if an error is encountered.

### 3.1 Setup
Since the database is being built from scratch a `DROP TABLE` statement is included that deletes 
all previously created tables each time the `video_games.sql` script is executed. This allows one
 to write the script in an iterative fashion, testing each new statement added to the script 
 without fear of damaging the database. 

```mysql
SET FOREIGN_KEY_CHECKS=0;
DROP TABLE IF EXISTS developer, game, game_developer, genre, platform,
                     publisher, rating, sale, region;
SET FOREIGN_KEY_CHECKS=1;
```

:bulb: Write and execute your script *one* statement at a time. Adopt an iterative development approach. Add a single SQL statement to the script and then run it. Add a new SQL statement to the script *only* after you confirm that all previous errors are addressed.

### 3.2 Create/populate tables with no foreign keys
Certain tables exist to provide "lookup" values for other tables. Creating and populating such 
tables is a straightforward process. If you only have a few rows to insert into a table (i.e., <= 20 rows) you can hard code the values in your SQL INSERT statement as in the example below:

```mysql
CREATE TABLE IF NOT EXISTS region (
  region_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  region_name VARCHAR(25) NOT NULL UNIQUE,
  PRIMARY KEY (region_id)
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;

INSERT IGNORE INTO region (region_name) VALUES
  ('Global'), ('North America'), ('Europe'), ('Japan'), ('Other');
```

If, on the other hand, you need to populate a lookup table with no foreign keys with a large 
number of rows consider using the Python [Pandas](https://pandas.pydata.org/) library to extract the column data out of your source file and then write it to a `csv` or `tsv` file. You can then call the file with your *.sql script and write the row data into the table using the [LOAD DATA LOCAL INFILE](https://dev.mysql.com/doc/refman/8.0/en/load-data.html) syntax.

:warning: Ensure that you have configured your MySQL server instance to permit the loading of text 
files.  Refer to the [Reading local files](./mysql-load_local_file_setup-win.md) tutorial for how
 to add the necessary `local-infile` setting. 

```mysql
CREATE TABLE IF NOT EXISTS publisher (
  publisher_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  publisher_name VARCHAR(100) NOT NULL UNIQUE,
  PRIMARY KEY (publisher_id)
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;

LOAD DATA LOCAL INFILE './output/video_games/video_game_publishers.csv'
INTO TABLE publisher
  CHARACTER SET utf8mb4
  FIELDS TERMINATED BY ',' ENCLOSED BY '"'
  LINES TERMINATED BY '\n'
  (publisher_name);
```

In the example above the file `video_game_publishers.csv` provides a list of publisher names.  
The `LOAD DATA LOCAL INFILE` portion of the statement reads rows from the csv file into the target 
table column `publisher_name`. 

The following row handling options are specified:

* `CHARACTER SET`
* `FIELDS TERMINATED BY`
* `ENCLOSED BY`
* `LINES TERMINATED BY`

Beyond specifying the incoming character set, both field and line terminators are specified with 
one or more escape sequence characters:

* `\n`: line feed (i.e., new line); macOS, Unix
* `\r`: carriage return
* `\r\n`: carriage return, line feed; MS Windows
* `\t`: tabulator (i.e., tab separator)

Specifying the `ENCLOSED BY` option is required when reading comma-delimited files that may 
include string values that contain one or more commas (',') as in the following example:

```
...
Deep Silver,
"Destination Software, Inc.",
Destineer,
...
```

:bulb: For macOS and Unix users you can identify the type of line breaks a text file contains with 
the 
`file` command (Windows requires installation of a Bash shell to gain this capability).

 ```commandline
$ file video_game_sales-20161222.csv
video_game_sales-20161222.csv: UTF-8 Unicode text, with CRLF line terminators
```

### 3.3 Create/Populate tables with foreign keys
If a table includes one or more foreign keys the task of populating the table with row data is 
usually a straightforward process. The following steps should usually suffice:

Ensure that the tables from which the foreign key values will be drawn are created and 
populated with row data. In the example below `genre`, `platform`, `publisher` and `rating` 
tables are required.

Create a temporary table that will serve as a temporary home for the flat file 
source data that specifies from one column to the next the entity relationships that you have chosen to model.

```mysql
CREATE TEMPORARY TABLE temp_game (
  game_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  game_name VARCHAR(255) NOT NULL,
  platform_name VARCHAR(50),
  year_released CHAR(4) NULL,
  genre_name VARCHAR(25) NULL,
  publisher_name VARCHAR(100) NULL,
  north_america_sales DECIMAL(5,2) NULL,
  europe_sales DECIMAL(5,2) NULL,
  japan_sales DECIMAL(5,2) NULL,
  other_sales DECIMAL(5,2) NULL,
  global_sales DECIMAL(5,2) NULL,
  critic_score CHAR(3) NULL,
  critic_count VARCHAR(10) NULL,
  user_score CHAR(3) NULL,
  user_count VARCHAR(10) NULL,
  developer_name VARCHAR(100) NULL,
  rating_name CHAR(4) NULL,
  PRIMARY KEY (game_id)
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;
```

Populate the table with row data read from the original source file.

:bulb: I recommend changing the original source file column names so that they match the database
 table column names.
 
Note in the example below an `IGNORE 1 LINES` option is added to the `LOAD DATA LOCAL INFILE` 
statement in order to skip the column headings located in the first row in the data set. The 
columns to be read are also specified. You can also skip a column in the source file by 
replacing a column name with a `@dummy` variable.

:warning: If columns in the source file include blank values you should use the SET statement and
 the IF() conditional check to replace each blank value encountered with `NULL`.

```mysql
LOAD DATA LOCAL INFILE './output/video_games/video_game_sales_trimmed.csv'
INTO TABLE temp_game
  CHARACTER SET utf8mb4
  -- FIELDS TERMINATED BY '\t'
  FIELDS TERMINATED BY ','
  ENCLOSED BY '"'
  LINES TERMINATED BY '\n'
  IGNORE 1 LINES
  (game_name, platform_name, year_released, genre_name,
  publisher_name, north_america_sales, europe_sales, japan_sales, other_sales,
  global_sales, critic_score, critic_count, user_score, user_count, developer_name,
  rating_name)

  SET game_name = IF(game_name = '', NULL, TRIM(game_name)),
  platform_name = IF(platform_name = '', NULL, TRIM(platform_name)),
  year_released = IF(year_released = '', NULL, year_released),
  genre_name = IF(genre_name = '', NULL, genre_name),
  publisher_name = IF(publisher_name = '', NULL, TRIM(publisher_name)),
  critic_score = IF(critic_score = '', NULL, critic_score),
  critic_count = IF(critic_count = '', NULL, critic_count),
  user_score = IF(user_score = '', NULL, user_score),
  user_count = IF(user_count = '', NULL, user_count),
  developer_name = IF(developer_name = '', NULL, TRIM(developer_name)),
  rating_name = IF(rating_name = '', NULL, TRIM(rating_name));
```

Create the actual table that will be used in "production" to store game-related attributes. Add foreign key and other constraints consistent with your logical data model.

```mysql
CREATE TABLE IF NOT EXISTS game (
    game_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
    game_name VARCHAR(255) NULL,
    platform_id INTEGER NULL,
    year_released INTEGER NULL,
    genre_id INTEGER NULL,
    publisher_id INTEGER NULL,
    north_america_sales DECIMAL(5, 2) NULL,
    europe_sales DECIMAL(5,2) NULL,
    japan_sales DECIMAL(5,2) NULL,
    other_sales DECIMAL(5,2) NULL,
    global_sales DECIMAL(5,2) NULL,
    critic_score INTEGER NULL,
    critic_count INTEGER NULL,
    user_score INTEGER NULL,
    user_count INTEGER NULL,
    developer_name VARCHAR(100) NULL,
    rating_id INTEGER NULL,
    PRIMARY KEY (game_id),
    FOREIGN KEY (platform_id) REFERENCES platform(platform_id)
    ON DELETE CASCADE ON UPDATE CASCADE,
    FOREIGN KEY (genre_id) REFERENCES genre(genre_id)
    ON DELETE CASCADE ON UPDATE CASCADE,
    FOREIGN KEY (publisher_id) REFERENCES publisher(publisher_id)
    ON DELETE CASCADE ON UPDATE CASCADE,
    FOREIGN KEY (rating_id) REFERENCES rating(rating_id)
    ON DELETE CASCADE ON UPDATE CASCADE
  )
  ENGINE=InnoDB
  CHARACTER SET utf8mb4
  COLLATE utf8mb4_0900_ai_ci;
```

Populate the table using an `INSERT INTO SELECT` statement.  In the example below, the 
`temp_game` table is joined to four "production" tables in order to return a result set that 
includes the foreign key integer values required for each row in the table.  Each join is based 
on an equality check of string values comprising the name of each entity.

The `game` table includes sales-related columns that will be migrated to another table later in 
the script. The table also includes a `developer_name` column that includes comma-delimited 
strings of developer companies sharing the design credits that will be split out into a separate 
many-to-many associative/junction table later in the script.

:bulb: Code defensively. Use the TRIM() function to guard against the inadvertent inclusion of whitespace in the string values.

```mysql
INSERT IGNORE INTO game
(
  game_name,
  platform_id,
  year_released,
  genre_id,
  publisher_id,
  north_america_sales,
  europe_sales,
  japan_sales,
  other_sales,
  global_sales,
  critic_score,
  critic_count,
  user_score,
  user_count,
  developer_name,
  rating_id
)
SELECT tg.game_name, plat.platform_id, CAST(tg.year_released AS UNSIGNED) AS year_released,
       g.genre_id, pub.publisher_id,
       tg.north_america_sales, tg.europe_sales, tg.japan_sales, tg.other_sales, tg.global_sales,
       CAST(tg.critic_score AS UNSIGNED) AS critic_score,
       CAST(tg.critic_count AS UNSIGNED) AS critic_count,
       CAST(tg.user_score AS UNSIGNED) AS user_score,
       CAST(tg.user_count AS UNSIGNED) AS user_count,
       tg.developer_name, r.rating_id
 FROM temp_game tg
      LEFT JOIN genre g
             ON TRIM(tg.genre_name) = TRIM(g.genre_name)
      LEFT JOIN platform plat
             ON TRIM(tg.platform_name) = TRIM(plat.platform_name)
      LEFT JOIN publisher pub
             ON TRIM(tg.publisher_name) = TRIM(pub.publisher_name)
      LEFT JOIN rating r
             ON TRIM(tg.rating_name) = TRIM(r.rating_name)
WHERE tg.game_name IS NOT NULL AND tg.game_name != ''
ORDER BY tg.global_sales DESC, tg.game_name, tg.year_released;
```

### 3.4 Efficient storage strategies
The `video_game_sales_trimmed.csv` includes several columns of sales data organized by region. To
 simplify the initial import the sales columns were loaded into the `game` table directly. This added thousands of `NULL` values to the `game` table since the sales numbers, while extensive, are nevertheless incomplete. A solution to this situation is to create a `region` table to store the regions and a `sale` table that reflects the many-to-many relationship between a game and a sales region. With these tables in place the sales data can be migrated from the `game` table to the `sale` table.
 
```mysql
CREATE TABLE IF NOT EXISTS sale (
  sale_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  game_id INTEGER NOT NULL,
  region_id INTEGER NOT NULL,
  total_sales DECIMAL(5,2),
  PRIMARY KEY (sale_id),
  FOREIGN KEY (game_id) REFERENCES game(game_id)
    ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (region_id) REFERENCES region(region_id)
    ON DELETE CASCADE ON UPDATE CASCADE
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;
```

Since each region's sales data is stored in the `game` table the `INTO INTO SELECT` statement 
used to populate the `sale` table employs the [UNION](https://dev.mysql.com/doc/refman/8.0/en/union.html) operator to combine the results from multiple `SELECT` statements into a single result set.

```mysql
INSERT IGNORE INTO sale
(
game_id,
region_id,
total_sales
)
SELECT g.game_id, 1 as region_id, g.global_sales AS total_sales
  FROM game g
 WHERE g.global_sales > 0.00
 UNION
SELECT g.game_id, 2 as region_id, g.north_america_sales AS total_sales
  FROM game g
 WHERE g.north_america_sales > 0.00
 UNION
SELECT g.game_id, 3 as region_id, g.europe_sales AS total_sales
  FROM game g
 WHERE g.europe_sales > 0.00
 UNION
SELECT g.game_id, 4 as region_id, g.japan_sales AS total_sales
  FROM game g
 WHERE g.japan_sales > 0.00
 UNION
SELECT g.game_id, 5 as region_id, g.other_sales AS total_sales
  FROM game g
 WHERE g.other_sales > 0.00;
```

### 3.5 Dealing with delimited values stored as strings 
Occasionally, spreadsheet and csv/tsv creators will store multiple values in single cells. This 
creates an interesting challenge when importing this data into a relational database. 

In the comma-delimited data snippet below, two "developer_name" strings include multiple values:

```
game_name,platform_name,year_of_release,genre_name,publisher_name,north_america_sales,europe_sales,japan_sales,other_sales,global_sales,critic_score,critic_count,user_score,user_count,developer_name,rating_name
...
Call of Duty: Modern Warfare 2,X360,2009,Shooter,Activision,8.52,3.59,0.08,1.28,13.47,94,100,6.3,2698,Infinity Ward,M
Call of Duty: Modern Warfare 3,PS3,2011,Shooter,Activision,5.54,5.73,0.49,1.57,13.32,88,39,3.2,5234,"Infinity Ward, Sledgehammer Games",M
Grand Theft Auto III,PS2,2001,Action,Take-Two Interactive,6.99,4.51,0.3,1.3,13.1,97,56,8.5,664,DMA Design,M
Super Smash Bros. Brawl,Wii,2008,Fighting,Nintendo,6.62,2.55,2.66,1.01,12.84,93,81,8.9,1662,Game Arts,T
Mario Kart 7,3DS,2011,Racing,Nintendo,5.03,4.02,2.69,0.91,12.66,85,73,8.2,632,"Retro Studios, Entertainment Analysis & Development Division",E
...
```

Extracting the four development companies included in the two strings (i.e., Infinity Ward, 
Sledgehammer Games, Retro Studios, and Entertainment Analysis & Development Division) will 
involve either pre-import work using the Pandas library or implementing the following approach in
 the *.sql script itself.

The script approach is described below. First, create a temporary table called `numbers` with a single column called `num` that is designated as the primary key.  Insert a range of integers, starting with 1 and ending with a maximum value greater than or equal to the number of "splits" required to parse the delimited strings that contain multiple values. 

```mysql
CREATE TEMPORARY TABLE numbers
  (
    num INTEGER NOT NULL UNIQUE,
    PRIMARY KEY (num)
  )
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;

INSERT IGNORE INTO numbers (num) VALUES
  (1), (2), (3), (4), (5), (6), (7), (8), (9), (10), (11), (12), (13), (14), (15);
```

Second, create a temporary table that will hold the individual values split out of the delimited string.

```mysql
CREATE TEMPORARY TABLE temp_game_developer
  (
    id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
    game_id INTEGER NOT NULL,
    developer_name VARCHAR(255) NOT NULL,
    PRIMARY KEY (id)
  )
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;
```

Third, utilize the following query (adjusted to your needs) to split the delimited string of 
values (e.g., game developer companies) by joining the source table on the `number` table with the `ON` clause returning a row whenever the character length of the delimited string *minus* the character length of the delimited string with all the delimiters removed is greater than or equal to the `number.num` value.

The `SELECT` clause provides the `game.game_id` and a `game.developer_name` value split out from 
the delimited string by the use of the `SUBSTRING_INDEX()` function.

```
SUBSTRING_INDEX(str, delim, count)
```

The MySQL [reference manual](https://dev.mysql.com/doc/refman/8.0/en/string-functions.html#function_substring-index) describes the function as follows:

> Returns the substring from string str before count occurrences of the delimiter delim. If count is positive, everything to the left of the final delimiter (counting from the left) is returned. If count is negative, everything to the right of the final delimiter (counting from the right) is returned. SUBSTRING_INDEX() performs a case-sensitive match when searching for delim.

The inner `SUBSTRING_INDEX()` function returns a substring of the `developer_name` value to the left of the targeted delimiter (`n.num`). The outer `SUBSTRING_INDEX()` ensures that the final value in the delimited string is properly returned. 

:bulb: To illustrate how the `SUBSTRING_INDEX(SUBSTRING_INDEX(g.developer_name, ',', n.num), ',',
 -1)` behaves run the following examples online using the w3schools [trymsql](https://www.w3schools.com/sql/trymysql.asp?filename=trysql_func_mysql_substring_index2) page.
 
#### Example 1
Execute the `SELECT SUBSTRING_INDEX()` statement twice. On the second run change the count value from 1 to 2.

```mysql
SELECT SUBSTRING_INDEX("Infinity Ward, Sledgehammer Games", ",", 1);
```

#### Example 2
Execute the second statement below twice, changing the inner `SUBSTRING_INDEX()` count from 1 to 2 
for the second run.  It should be clear why the outer `SUBSTRING_INDEX(SUBSTRING_INDEX(...), ",
", -1)` is required:

```mysql
SELECT SUBSTRING_INDEX(SUBSTRING_INDEX("Infinity Ward, Sledgehammer Games", ",", 1), ",", -1);

```

Now you should be able to comprehend the purpose of the following query:

```mysql
INSERT IGNORE INTO temp_game_developer (game_id, developer_name)
SELECT DISTINCT g.game_id,
       TRIM(SUBSTRING_INDEX(SUBSTRING_INDEX(g.developer_name, ',', n.num), ',', -1))
       AS developer_name
  FROM numbers n
       INNER JOIN game g
               ON CHAR_LENGTH(g.developer_name) - CHAR_LENGTH(REPLACE(g.developer_name, ',', ''))
                  >= n.num - 1
 ORDER BY g.game_id, developer_name;
```

Once the `temp_game_developer` table is populated the "production" `developer` table can be populated 
with an `INSERT INTO SELECT` statement that provides a record set of distinct developer 
organizations. 

```mysql
CREATE TABLE IF NOT EXISTS developer (
  developer_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  developer_name VARCHAR(100) NOT NULL UNIQUE,
  PRIMARY KEY (developer_id)
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;

INSERT IGNORE INTO developer (developer_name)
SELECT DISTINCT TRIM(tgd.developer_name) AS developer_name
  FROM temp_game_developer tgd
 ORDER BY developer_name;
```

With the `developer` table populated and the primary keys in place, the associative/junction 
`game_developer` table can be created with a Django-friendly `game_developer_id` primary key 
provided in place of a `game_id` and `developer_id` composite primary key.

```mysql
CREATE TABLE IF NOT EXISTS game_developer (
  game_developer_id INTEGER NOT NULL AUTO_INCREMENT UNIQUE,
  game_id INTEGER NOT NULL,
  developer_id INTEGER NOT NULL,
  PRIMARY KEY (game_developer_id),
  FOREIGN KEY (game_id) REFERENCES game(game_id)
    ON DELETE CASCADE ON UPDATE CASCADE,
  FOREIGN KEY (developer_id) REFERENCES developer(developer_id)
    ON DELETE CASCADE ON UPDATE CASCADE
)
ENGINE=InnoDB
CHARACTER SET utf8mb4
COLLATE utf8mb4_0900_ai_ci;
```

The `game_id` and `developer_id` foreign key values can now be inserted into the `game_developer` 
table via a `INSERT INTO SELECT` statement that joins the `temp_game_developer` table with the 
`developer` table. The `developer_id` key is pulled in by the equality check between 
`temp_game_developer.developer_name` and the `developer.developer_name`.

```mysql
INSERT IGNORE INTO game_developer (game_id, developer_id)
SELECT tgd.game_id, d.developer_id
  FROM temp_game_developer tgd
       INNER JOIN developer d
               ON TRIM(tgd.developer_name) = TRIM(d.developer_name)
 ORDER BY tgd.game_id, d.developer_id;
```

## 4.0 Clean up
The final step involves dropping redundant table columns as well as temporary tables. The statements are grouped together at the end of the script for illustrative purposes only. The preferred practice is to issue the `DROP` statements at a point in the script when a temporary table is no longer needed or a table column is rendered redundant.

```mysql
ALTER TABLE game
      DROP COLUMN north_america_sales,
      DROP COLUMN europe_sales,
      DROP COLUMN japan_sales,
      DROP COLUMN other_sales,
      DROP COLUMN global_sales,
      DROP COLUMN developer_name;

DROP TEMPORARY TABLE numbers;
DROP TEMPORARY TABLE temp_game;
DROP TEMPORARY TABLE temp_game_developer;
```

## 5.0 Gotchas
A number of Windows users and a Mac user have reported file encoding issues (e.g., lost or mangled "special" characters) in string data imported into MySQL.  In each case the user had opened and/or edited the .csv file in Excel prior to importing the data into MySQL.

__Recommendation:__ avoid opening/editing your .csv files in Excel.  Use another editor such as Atom to view/edit the .csv prior to loading the data into your database. That said, I have successfully read in data from an Excel *.xlsx file using Pandas with no resulting encoding issues.  See the SI-664 scripts `met_inspector.py` script:

```python
source_path = os.path.join('input', 'csv', 'met_cleaned_seroka-orig.xlsx')
source_data_frame = pd.read_excel(source_path, sheet_name='all_data', header=0)
source_data_frame_trimmed = trim_columns(source_data_frame)
```

You can also install the `chardet` package and use it to discover your source file's encoding and then pass the encoding value to the Pandas .read_csv() method in order to ensure that the file is read in with the correct encoding:

```python
source_path = os.path.join('input', 'csv', 'met_data_seroka-orig.csv')
encoding = find_encoding(source_path)
source_data_frame = read_csv(source_path, encoding, '\t')
```

Note: the above code snippet is currently commented out but it works. 

A number of Windows users have also reported encountering string value mismatches when comparing otherwise matching strings (e.g., "Detroit" = "Detroit") sourced from two or more .csv files.  The mismatches usually occur between string values sourced from a Pandas-generated .csv file versus string values sourced from the original .csv file obtained from Kaggle or some other open data set provider.

The issue manifests itself when attempting to retrieve an entity's foreign key value in one table by matching on the entity's string name in another table, as in the following example:

```mysql
SELECT c.city_id, th.hospital_name
   FROM temp_hospital th
        INNER JOIN city c
                ON TRIM(th.city_name) = TRIM(c.city_name)
ORDER BY th.hospital_name;
```

An empty result set is usually a mismatch in string lengths (as measured in bytes) that is otherwise invisible to the human eye. Using the `TRIM()` function does not resolve the string length mismatch. You can check string lengths using the `LENGTH()` function:

#### Temp table based on original source file

```commandline
mysql> SELECT DISTINCT th.city_name, LENGTH(th.city_name) AS string_length
-> FROM temp_hospital th
-> ORDER BY th.city_name;
+-----------+---------------+
| city_name | string_length |
+-----------+---------------+
| ABBEVILLE | 10 |
| ABERDEEN | 9 |
| ABILENE | 8 |
| ABINGDON | 9 |
| ABINGTON | 9 |
+-----------+---------------+
5 rows in set (0.01 sec)
```

#### Table populated from a .csv file containing values extracted from the source file by Pandas 

```commandline
mysql> SELECT c.city_name, LENGTH(c.city_name) AS string_length
-> FROM city c
-> ORDER BY c.city_name;
+-----------+---------------+
| city_name | string_length |
+-----------+---------------+
| ABBEVILLE | 9 |
| ABERDEEN | 8 |
| ABILENE | 7 |
| ABINGDON | 8 |
| ABINGTON | 8 |
+-----------+---------------+
5 rows in set (0.00 sec)
```

__Recommendation:__ If you detect a mismatch in string lengths use Pandas to

1. strip() each and every string value in the source .csv file.
2. write out a new copy of the stripped version of the source .csv for use by MySQL (retain the original source file as is).

By doing this you align your source data set string values with string values extracted by Pandas
 and written to other .csv files for use by MySQL. Example code is available in the SI664-scripts repo.  See in particular the Python script `video_games_inspector.py`:
 
```python
source_data_frame_trimmed = trim_columns(source_data_frame)

def trim_columns(data_frame)
    trim = lambda x: x.strip() if type(x) is str else x
    return data_frame.applymap(trim)
``` 

I watched a Windows user download Pandas-generated csv files from the SI-664 scripts repo and then copy the files from one directory to another in preparation for reading the data into MySQL via a `LOAD DATA LOCAL INFILE` operation.  The `LOAD` operation succeeded but the Windows copy operation appears to have changed the string lengths of the copied csv file data resulting in string mismatches in subsequent `SELECT` queries.  We resolved this issue by downloading the csv files directly into the target directory (no prior moves). If you are a Windows user, be very careful in how you handle your csv files.